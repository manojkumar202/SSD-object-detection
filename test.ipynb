{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mka219/.conda/envs/image_segmentation/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import *\n",
    "from model import *\n",
    "from utils import *\n",
    "from scipy.special import softmax\n",
    "class_num = 4 #cat dog person background\n",
    "\n",
    "num_epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "boxs_default = default_box_generator([10,5,3,1], [0.2,0.4,0.6,0.8], [0.1,0.3,0.5,0.7])\n",
    "\n",
    "\n",
    "#Create network\n",
    "network = SSD(class_num)\n",
    "network.cuda()\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference\n"
     ]
    }
   ],
   "source": [
    "dataset_test = COCO(\"data/test/images/\", \"data/test/annotations/\", class_num, boxs_default, train = \"test\", image_size=320)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "711"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.load_state_dict(torch.load('network_3feb.pth'))\n",
    "network.eval()\n",
    "len(dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bound_box_class=[]\n",
    "\n",
    "for i, data in enumerate(dataloader_test, 0):\n",
    "    images_, filename= data\n",
    "    images = images_.cuda()\n",
    "    \n",
    "    pred_confidence, pred_box = network(images)\n",
    "\n",
    "    pred_confidence_ = pred_confidence[0].detach().cpu().numpy()\n",
    "    pred_box_ = pred_box[0].detach().cpu().numpy()\n",
    "    \n",
    "    pred_confidence_,pred_box_, ogn_pred_box = non_maximum_suppression(pred_confidence_,pred_box_,boxs_default)\n",
    "    \n",
    "    #TODO: save predicted bounding boxes and classes to a txt file.\n",
    "    #you will need to submit those files for grading this assignment\n",
    "    #print(filename[0])\n",
    "    \n",
    "    visualize_pred(\"inference\", pred_confidence_, pred_box_, [], [], images_[0].numpy(), boxs_default, ogn_pred_box, final_bound_box_class)\n",
    "    #print(final_bound_box_class[i])\n",
    "    final_bound_box_class[i].insert(0,filename[0])\n",
    "    #print(final_bound_box_class)\n",
    "    #if i==20:\n",
    "    #    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predictions.txt', 'w') as f:\n",
    "    for line in final_bound_box_class:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a8b601629eddc02b81200d964090c353cd8b401e8d28ee3f0b6059027507a26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
